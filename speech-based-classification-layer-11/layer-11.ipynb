{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of feature names\n",
    "\n",
    "FEATURES = []\n",
    "for i in range(1, 769):\n",
    "  FEATURES.append('feature_' + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of label names\n",
    "\n",
    "LABELS = ['label_1', 'label_2', 'label_3', 'label_4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_valid = pd.read_csv('valid.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing values\n",
    "\n",
    "missing_values_sum =  df_train.isnull().sum()\n",
    "missing_values_sum[missing_values_sum > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label 2 has missing values, missing values need to be removed when generating the training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = dict()\n",
    "\n",
    "for label in LABELS:\n",
    "  data_dict[label] = dict()\n",
    "  \n",
    "  data_dict[label]['x_train'] = df_train[df_train[label].notna()][FEATURES].values\n",
    "  data_dict[label]['y_train'] = df_train[df_train[label].notna()][label].values\n",
    "  data_dict[label]['x_valid'] = df_valid[df_valid[label].notna()][FEATURES].values\n",
    "  data_dict[label]['y_valid'] = df_valid[df_valid[label].notna()][label].values\n",
    "  data_dict[label]['x_test'] = df_test[FEATURES].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to write the predictions to a csv file\n",
    "\n",
    "def write_to_csv(df_test, file_name):\n",
    "  # index.name = ID and start index from 1\n",
    "\n",
    "  df_test.index += 1\n",
    "  df_test.index.name = 'ID'\n",
    "  df_test.to_csv(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without any feature engineering, hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors=3, weights='distance', n_jobs=7)\n",
    "\n",
    "df_test_pred_knn = pd.DataFrame()\n",
    "\n",
    "for label in LABELS:\n",
    "  knn_model.fit(data_dict[label]['x_train'], data_dict[label]['y_train'])\n",
    "  knn_pred = knn_model.predict(data_dict[label]['x_valid'])\n",
    "  print('accuracy_score for {}: '.format(label), accuracy_score(data_dict[label]['y_valid'], knn_pred))\n",
    "\n",
    "  knn_test_pred = knn_model.predict(data_dict[label]['x_test'])\n",
    "  df_test_pred_knn[label] = knn_test_pred\n",
    "\n",
    "df_test_pred_knn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_csv(df_test_pred_knn, 'submission_initial_knn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "\n",
    "df_test_pred_svc = pd.DataFrame()\n",
    "\n",
    "for label in LABELS:\n",
    "  svc_model.fit(data_dict[label]['x_train'], data_dict[label]['y_train'])\n",
    "  svc_pred = svc_model.predict(data_dict[label]['x_valid'])\n",
    "  print('accuracy_score for {}: '.format(label), accuracy_score(data_dict[label]['y_valid'], svc_pred))\n",
    "\n",
    "  svc_test_pred = svc_model.predict(data_dict[label]['x_test'])\n",
    "  df_test_pred_svc[label] = svc_test_pred\n",
    "\n",
    "df_test_pred_svc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_csv(df_test_pred_svc, 'submission_initial_svc.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the distribution of the labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 8))\n",
    "\n",
    "for i, label in enumerate(LABELS):\n",
    "    row = i // 2\n",
    "    col = i % 2\n",
    "    ax = axes[row, col]\n",
    "    sns.countplot(data=df_train, x=label, ax=ax)\n",
    "    ax.set_title(f'Distribution of {label}')\n",
    "    ax.set_xlabel(label)\n",
    "    ax.set_ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "label1 shows a balanced distribution, label3 and label4 have one dominant class each, label2 has a skewed distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model_pca = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "\n",
    "df_test_pred = pd.DataFrame()\n",
    "\n",
    "pca = PCA(n_components=0.97,svd_solver='full')\n",
    "\n",
    "for label in LABELS:\n",
    "  x_train_pca = pca.fit_transform(data_dict[label]['x_train'])\n",
    "  svc_model_pca.fit(x_train_pca, data_dict[label]['y_train'])\n",
    "\n",
    "  x_valid_pca = pca.transform(data_dict[label]['x_valid'])\n",
    "  svc_pred = svc_model_pca.predict(x_valid_pca)\n",
    "  print('accuracy_score for {}: '.format(label), accuracy_score(data_dict[label]['y_valid'], svc_pred))\n",
    "\n",
    "  x_test_pca = pca.transform(data_dict[label]['x_test'])\n",
    "  svc_test_pred = svc_model_pca.predict(x_test_pca)\n",
    "  df_test_pred[label] = svc_test_pred\n",
    "\n",
    "df_test_pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# halving grid search for best parameters\n",
    "\n",
    "param_grid = {'C': [1, 10, 100]}\n",
    "base_estimator = SVC(gamma='scale', kernel='rbf', random_state=42)\n",
    "\n",
    "search = HalvingGridSearchCV(base_estimator, param_grid, cv=5, verbose=1, n_jobs=7)\n",
    "search.fit(data_dict['label_1']['x_train'], data_dict['label_1']['y_train'])\n",
    "\n",
    "print(search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model_after_halving_search = SVC(kernel='rbf', gamma='scale', C=100, random_state=42)\n",
    "\n",
    "df_test_pred_after_halving_search_svc = pd.DataFrame()\n",
    "\n",
    "for label in LABELS:\n",
    "  svc_model_after_halving_search.fit(data_dict[label]['x_train'], data_dict[label]['y_train'])\n",
    "\n",
    "  svc_pred = svc_model_after_halving_search.predict(data_dict[label]['x_valid'])\n",
    "  print('accuracy_score for {}: '.format(label), accuracy_score(data_dict[label]['y_valid'], svc_pred))\n",
    "\n",
    "  svc_test_pred_after_halving_search = svc_model_after_halving_search.predict(data_dict[label]['x_test'])\n",
    "  df_test_pred_after_halving_search_svc[label] = svc_test_pred_after_halving_search\n",
    "\n",
    "df_test_pred_after_halving_search_svc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_csv(df_test_pred_after_halving_search_svc, 'submission_tune_svc.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA + GridSearchCV + SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty dataframe for test predictions\n",
    "df_test_pred = pd.DataFrame()\n",
    "\n",
    "# PCA with 95% variance\n",
    "pca = PCA(n_components=0.95,svd_solver='full')\n",
    "\n",
    "for label in LABELS:\n",
    "  # PCA fit and transform on train data\n",
    "  x_train_pca = pca.fit_transform(data_dict[label]['x_train'])\n",
    "  # PCA transform on valid data\n",
    "  x_valid_pca = pca.transform(data_dict[label]['x_valid'])\n",
    "  # PCA transform on test data\n",
    "  x_test_pca = pca.transform(data_dict[label]['x_test'])\n",
    "\n",
    "  # grid search for best parameters\n",
    "  param_grid = {\n",
    "                'C': [1, 10, 20, 30, 40, 50, 100],\n",
    "                'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "                'gamma': ['scale', 'auto']\n",
    "                }\n",
    "  base_estimator = SVC(random_state=42)\n",
    "  search = HalvingGridSearchCV(base_estimator, param_grid, cv=5, verbose=1, n_jobs=7)\n",
    "  search.fit(x_train_pca, data_dict[label]['y_train'])\n",
    "\n",
    "  print(search.best_params_)\n",
    "  \n",
    "  # SVC model with best parameters\n",
    "  svc_model_pca_and_grid_search = SVC(**search.best_params_, random_state=42)\n",
    "  # fit the model\n",
    "  svc_model_pca_and_grid_search.fit(x_train_pca, data_dict[label]['y_train'])\n",
    "  # predict on valid data\n",
    "  svc_pred = svc_model_pca_and_grid_search.predict(x_valid_pca)\n",
    "  print('accuracy_score for {}: '.format(label), accuracy_score(data_dict[label]['y_valid'], svc_pred))\n",
    "  # predict on test data\n",
    "  svc_test_pred = svc_model_pca_and_grid_search.predict(x_test_pca)\n",
    "  df_test_pred[label] = svc_test_pred\n",
    "\n",
    "df_test_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_csv(df_test_pred, 'submission_tune_svc_pca.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StandardScaler + SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "svc_model_after_halving_search = SVC(kernel='rbf', gamma='scale', C=100, random_state=42)\n",
    "\n",
    "df_test_pred = pd.DataFrame()\n",
    "\n",
    "for label in LABELS:\n",
    "  scaler.fit(data_dict[label]['x_train'])\n",
    "  x_train = scaler.transform(data_dict[label]['x_train'])\n",
    "  x_valid = scaler.transform(data_dict[label]['x_valid'])\n",
    "  x_test = scaler.transform(data_dict[label]['x_test'])\n",
    "\n",
    "  svc_model_after_halving_search.fit(x_train, data_dict[label]['y_train'])\n",
    "\n",
    "  svc_pred = svc_model_after_halving_search.predict(x_valid)\n",
    "  print('accuracy_score for {}: '.format(label), accuracy_score(data_dict[label]['y_valid'], svc_pred))\n",
    "\n",
    "  svc_test_pred = svc_model_after_halving_search.predict(x_test)\n",
    "  df_test_pred[label] = svc_test_pred\n",
    "\n",
    "df_test_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_csv(df_test_pred, 'submission_scaled_svc.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer steps\n",
    "  - Scale using StandardScaler\n",
    "  - SVC(kernel='rbf', gamma='scale', C=100, random_state=42) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final model for the layer in layer-11-final.ipynb**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
